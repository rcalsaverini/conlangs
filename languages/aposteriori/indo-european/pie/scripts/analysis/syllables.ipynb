{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ph₂\n",
      "teːr\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from syllable_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"\"\"\n",
    "words\n",
    "mh₂.teːr\n",
    "ph₂.téːr\n",
    "bʰréh₂.teːr\n",
    "swé.soːr\n",
    "dʰugh₂.téːr\n",
    "suh₁.nús\n",
    "h₂.né.poːts\n",
    "h₁.lewdʰ\n",
    "dʰgʰe.móːn\n",
    "pó.tis\n",
    "wih₁.rós\n",
    "gʷéːn\n",
    "gʰós.tis\n",
    "déms\n",
    "h₂égh₂\n",
    "túh₂\n",
    "wéy\n",
    "só\n",
    "h₁óy.nos\n",
    "dwoh₁\n",
    "tré.yes\n",
    "kʷe.twó.res\n",
    "pén.kʷe\n",
    "swéks\n",
    "sép.tem\n",
    "h₁ok.tóːw\n",
    "h₁.néw.nh₂\n",
    "dék.mh₃t\n",
    "krep\n",
    "káput\n",
    "h₃.dón.th₂s\n",
    "néh₂s\n",
    "póːds\n",
    "h₃.nóːgʰs\n",
    "h₃.bʰrúh₂s\n",
    "pé.th₂r\n",
    "h₂óst\n",
    "h₂ous\n",
    "h₃ókʷs\n",
    "h₁óh₃s\n",
    "kerd\n",
    "gʰésr\n",
    "kerd\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(StringIO(words))\n",
    "words = df.words.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_next_character(word):\n",
    "    for name, regex in regexes.items():\n",
    "        match = regex.match(word)\n",
    "        if match is not None:\n",
    "            character = match.group()\n",
    "            rest = word[match.end():]\n",
    "            return character, name, rest\n",
    "    else:\n",
    "        raise ValueError(f\"Not Found: {word}\")\n",
    "\n",
    "def get_next_syllable(word):\n",
    "    syllable_type = []\n",
    "    syllable_chars = []\n",
    "    rest = word\n",
    "    while len(rest) > 0:\n",
    "        character, name, rest = get_next_character(rest)\n",
    "        if name == \"SYLLABLE_SEPARATOR\":\n",
    "            return \"\".join(syllable_chars), \"\".join(syllable_type), rest\n",
    "        else:\n",
    "            syllable_chars.append(character)\n",
    "            syllable_type.append(f\"[{name}]\")\n",
    "    else:\n",
    "        return \"\".join(syllable_chars), \"\".join(syllable_type), rest\n",
    "\n",
    "def word_to_syllables(word):\n",
    "    syllables = []\n",
    "    rest = word\n",
    "    while len(rest) > 0:\n",
    "        syllable_chars, syllable_type, rest = get_next_syllable(rest)\n",
    "        syllables.append((syllable_chars, syllable_type))\n",
    "    return syllables\n",
    "\n",
    "def group_syllables_by_type(words):\n",
    "    unique_syllables = sorted({(syl, syl_type) for word in words for syl, syl_type in word_to_syllables(word)}, key=lambda x: (x[1], x[0]))\n",
    "    return {\n",
    "        syl_type: list([syl for syl, syl_type in syls])\n",
    "        for syl_type, syls in it.groupby(unique_syllables, key=lambda x: x[1])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h₂né', '[LARYNGEAL][CONSONANT][VOWEL_LIKE]'),\n",
       " ('poːts', '[CONSONANT][VOWEL_LIKE][CONSONANT][CONSONANT]')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_syllables(\"h₂né.poːts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONSONANT][CONSONANT][VOWEL_LIKE]\n",
      "\tdʰgʰe, swé, tré, twó\n",
      "[CONSONANT][CONSONANT][VOWEL_LIKE][CONSONANT]\n",
      "\tkrep\n",
      "[CONSONANT][CONSONANT][VOWEL_LIKE][CONSONANT][CONSONANT]\n",
      "\tswéks\n",
      "[CONSONANT][CONSONANT][VOWEL_LIKE][LARYNGEAL]\n",
      "\tbʰréh₂, dwoh₁\n",
      "[CONSONANT][CONSONANT][VOWEL_LIKE][LARYNGEAL][CONSONANT]\n",
      "\tbʰrúh₂s\n",
      "[CONSONANT][LARYNGEAL]\n",
      "\tmh₂, nh₂, ph₂\n",
      "[CONSONANT][LARYNGEAL][CONSONANT]\n",
      "\tmh₃t, th₂r, th₂s\n",
      "[CONSONANT][VOWEL_LIKE]\n",
      "\tkʷe, né, pé, pó, só\n",
      "[CONSONANT][VOWEL_LIKE][CONSONANT]\n",
      "\tdék, dón, gʰós, gʷéːn, móːn, nos, néw, nús, pén, res, rós, soːr, sép, tem, teːr, tis, téːr, tóːw, wéy, yes\n",
      "[CONSONANT][VOWEL_LIKE][CONSONANT][CONSONANT]\n",
      "\tdéms, gʰésr, kerd, lewdʰ, nóːgʰs, poːts, póːds\n",
      "[CONSONANT][VOWEL_LIKE][CONSONANT][LARYNGEAL]\n",
      "\tdʰugh₂\n",
      "[CONSONANT][VOWEL_LIKE][CONSONANT][VOWEL_LIKE][CONSONANT]\n",
      "\tkáput\n",
      "[CONSONANT][VOWEL_LIKE][LARYNGEAL]\n",
      "\tsuh₁, túh₂, wih₁\n",
      "[CONSONANT][VOWEL_LIKE][LARYNGEAL][CONSONANT]\n",
      "\tnéh₂s\n",
      "[LARYNGEAL]\n",
      "\th₁, h₂, h₃\n",
      "[LARYNGEAL][VOWEL_LIKE][CONSONANT]\n",
      "\th₁ok, h₁óy\n",
      "[LARYNGEAL][VOWEL_LIKE][CONSONANT][CONSONANT]\n",
      "\th₂óst, h₃ókʷs\n",
      "[LARYNGEAL][VOWEL_LIKE][CONSONANT][LARYNGEAL]\n",
      "\th₂égh₂\n",
      "[LARYNGEAL][VOWEL_LIKE][LARYNGEAL][CONSONANT]\n",
      "\th₁óh₃s\n",
      "[LARYNGEAL][VOWEL_LIKE][VOWEL_LIKE][CONSONANT]\n",
      "\th₂ous\n"
     ]
    }
   ],
   "source": [
    "for (syl_type, syls) in group_syllables_by_type(words).items():\n",
    "    print(syl_type)\n",
    "    print(\"\\t\" + \", \".join(syls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD = (\n",
    "    SYLLABLE.capture(\"syllable\").match_at_start() + \n",
    "    Indefinite(SYLLABLE, is_greedy=False)\\\n",
    "        .capture(\"rest\").match_at_end()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_word(word):\n",
    "    syllables = []    \n",
    "    rest = word\n",
    "    while len(rest) > 0:\n",
    "        captures = WORD.get_named_captures(rest)\n",
    "        for capture in captures:\n",
    "            rest = capture[\"rest\"]\n",
    "            syllables.append(capture[\"syllable\"])\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mh₂', 'teːr']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_word(\"mh₂teːr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
